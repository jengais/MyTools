{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "window = Tk()\n",
    "\n",
    "window.title(\"Hello world\")\n",
    "window.geometry('800x800')\n",
    "\n",
    "lbl = Label(window, text=\"Nice\", font=(\"Arial Bold\", 50))\n",
    "lbl.grid(column=0, row=0)\n",
    "\n",
    "def clicked():\n",
    "    lbl.configure(text=\"Button was clicked !!\")\n",
    "\n",
    "btn = Button(window, text=\"Click Me\", bg=\"orange\", fg=\"red\", font=(\"Arial Bold\", 50), command=clicked)\n",
    "btn.grid(column=1, row=0)\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length:  42181\n",
      "Dataset Shape:  (42181, 16)\n",
      "Dataset:      0             1        2          3        4        5        6     7   \\\n",
      "0  age           job  marital  education  default  balance  housing  loan   \n",
      "1   58    management  married   tertiary       no     2143      yes    no   \n",
      "2   44    technician   single  secondary       no       29      yes    no   \n",
      "3   33  entrepreneur  married  secondary       no        2      yes   yes   \n",
      "4   47   blue-collar  married    unknown       no     1506      yes    no   \n",
      "\n",
      "        8    9      10        11        12        13        14     15  \n",
      "0  contact  day  month  duration  campaign  previous  poutcome  class  \n",
      "1  unknown    5    may       261         1         0   unknown     no  \n",
      "2  unknown    5    may       151         1         0   unknown     no  \n",
      "3  unknown    5    may        76         1         0   unknown     no  \n",
      "4  unknown    5    may        92         1         0   unknown     no  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3331: DtypeWarning: Columns (0,5,9,11,12,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d51850130996>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;31m# Calling main function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-d51850130996>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Building Phase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitdataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[0mclf_gini\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_using_gini\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0mclf_entropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarin_using_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-d51850130996>\u001b[0m in \u001b[0;36msplitdataset\u001b[1;34m(balance_data)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# Splitting the dataset into train and test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     X_train, X_test, y_train, y_test = train_test_split(  \n\u001b[0m\u001b[0;32m     40\u001b[0m     X, Y, test_size = 0.3, random_state = 100) \n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "#from sklearn.cross_validation import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "  \n",
    "# Function importing Dataset \n",
    "def importdata(): \n",
    "    balance_data = pd.read_csv(\"C:\\\\NewFoulder\\SCE\\שנה ב\\סמסטר ב\\מבוא לכריית נתונים\\HW\\\\4\\\\train.csv\", \n",
    "    sep= ',', header = None) \n",
    "    \n",
    "    \n",
    "#     for i in range(len(balance_data)+1):\n",
    "#         balance_data[1][i+1]=0\n",
    "       \n",
    "    #balance_data[1][1] = None\n",
    "    #print(balance_data[1][1])\n",
    "    # Printing the dataswet shape \n",
    "    print (\"Dataset Length: \", len(balance_data)) \n",
    "    print (\"Dataset Shape: \", balance_data.shape) \n",
    "      \n",
    "    # Printing the dataset obseravtions \n",
    "    print (\"Dataset: \",balance_data.head()) \n",
    "    \n",
    "    #balance_data=balance_data.drop('job',axis=1)\n",
    "\n",
    "    return balance_data \n",
    "  \n",
    "# Function to split the dataset \n",
    "def splitdataset(balance_data): \n",
    "  \n",
    "    # Separating the target variable \n",
    "    X = balance_data.values[:, 1:5] \n",
    "    Y = balance_data.values[:, 0] \n",
    "  \n",
    "    # Splitting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(  \n",
    "    X, Y, test_size = 0.3, random_state = 100) \n",
    "      \n",
    "    return X, Y, X_train, X_test, y_train, y_test \n",
    "      \n",
    "# Function to perform training with giniIndex. \n",
    "def train_using_gini(X_train, X_test, y_train): \n",
    "  \n",
    "    # Creating the classifier object \n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "            random_state = 100,max_depth=3, min_samples_leaf=5) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    return clf_gini \n",
    "      \n",
    "# Function to perform training with entropy. \n",
    "def tarin_using_entropy(X_train, X_test, y_train): \n",
    "  \n",
    "    # Decision tree with entropy \n",
    "    clf_entropy = DecisionTreeClassifier( \n",
    "            criterion = \"entropy\", random_state = 100, \n",
    "            max_depth = 3, min_samples_leaf = 5) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_entropy.fit(X_train, y_train) \n",
    "    return clf_entropy \n",
    "  \n",
    "  \n",
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object): \n",
    "  \n",
    "    # Predicton on test with giniIndex \n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    print(\"Predicted values:\") \n",
    "    print(y_pred) \n",
    "    return y_pred \n",
    "      \n",
    "# Function to calculate accuracy \n",
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy : \", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "      \n",
    "    print(\"Report : \", \n",
    "    classification_report(y_test, y_pred)) \n",
    "  \n",
    "# Driver code \n",
    "def main(): \n",
    "      \n",
    "    # Building Phase \n",
    "    data = importdata() \n",
    "    X, Y, X_train, X_test, y_train, y_test = splitdataset(data) \n",
    "    clf_gini = train_using_gini(X_train, X_test, y_train) \n",
    "    clf_entropy = tarin_using_entropy(X_train, X_test, y_train) \n",
    "      \n",
    "    # Operational Phase \n",
    "    print(\"Results Using Gini Index:\") \n",
    "      \n",
    "    # Prediction using gini \n",
    "    y_pred_gini = prediction(X_test, clf_gini) \n",
    "    cal_accuracy(y_test, y_pred_gini) \n",
    "      \n",
    "    print(\"Results Using Entropy:\") \n",
    "    # Prediction using entropy \n",
    "    y_pred_entropy = prediction(X_test, clf_entropy) \n",
    "    cal_accuracy(y_test, y_pred_entropy) \n",
    "      \n",
    "      \n",
    "# Calling main function \n",
    "if __name__==\"__main__\": \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-166be3819a61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \"\"\"\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'entropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m###########################################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    878\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "\n",
    "#Import the DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Import the Zoo Dataset\n",
    "\"\"\"\n",
    "\n",
    "#Import the dataset \n",
    "dataset = pd.read_csv(\"C:\\\\NewFoulder\\SCE\\שנה ב\\סמסטר ב\\מבוא לכריית נתונים\\HW\\\\4\\\\train.csv\")\n",
    "#We drop the animal names since this is not a good feature to split the data on\n",
    "dataset=dataset.drop('job',axis=1)\n",
    "dataset=dataset.drop('marital',axis=1)\n",
    "dataset=dataset.drop('education',axis=1)\n",
    "dataset=dataset.drop('default',axis=1)\n",
    "dataset=dataset.drop('housing',axis=1)\n",
    "dataset=dataset.drop('loan',axis=1)\n",
    "dataset=dataset.drop('month',axis=1)\n",
    "dataset=dataset.drop('contact',axis=1)\n",
    "dataset=dataset.drop('poutcome',axis=1)  \n",
    "\n",
    "dataset.fillna(0)\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Split the data into a training and a testing set\n",
    "\"\"\"\n",
    "\n",
    "train_features = dataset.iloc[:80,:-1]\n",
    "test_features = dataset.iloc[80:,:-1]\n",
    "train_targets = dataset.iloc[:80,-1]\n",
    "test_targets = dataset.iloc[80:,-1]\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Train the model\n",
    "\"\"\"\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion = 'entropy').fit(train_features,train_targets)\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Predict the classes of new, unseen data\n",
    "\"\"\"\n",
    "prediction = tree.predict(test_features)\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Check the accuracy\n",
    "\"\"\"\n",
    "\n",
    "print(\"The prediction accuracy is: \",tree.score(test_features,test_targets)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
